{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Mount Google Drive (optional)"
      ],
      "metadata": {
        "id": "fI00-KuddN2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "# os.chdir(\"/content/drive/MyDrive/....\")  # file path\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "Uf6ucZcj6kpK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5ef8e4b-8c20-40d8-a317-0c285edff541"
      },
      "execution_count": 441,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **HW2 : Decision Tree and Random Forest**\n",
        "In *assignment 2*, you need to finish :\n",
        "\n",
        "1. Basic Part : Implement a **Decision Tree** model and predict whether the patients in the validation set have diabetes\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Calculate the Entropy and Information Gain\n",
        "> * Step 3 : Find the Best Split\n",
        "> * Step 4 : Split into 2 branches\n",
        "> * Step 5 : Build decision tree\n",
        "> * Step 6 : Save the answers from step2 to step5\n",
        "> * Step 7 : Split data into training set and validation set\n",
        "> * Step 8 : Train a decision tree model with training set\n",
        "> * Step 9 : Predict the cases in the *validation set* by using the model trained in *Step8*\n",
        "> * Step 10 : Calculate the f1-score of your predictions in *Step9*\n",
        "> * Step 11 : Write the Output File\n",
        "\n",
        "2. Advanced Part : Build a **Random Forest** model to make predictions\n",
        "> * Step 1 : Load the input data\n",
        "> * Step 2 : Load the test data\n",
        "> * Step 3 : Build a random forest\n",
        "> * Step 4 : Predict the cases in the test data by using the model trained in *Step3*\n",
        "> * Step 5 : Save the predictions(from *Step 4*) in a csv file\n",
        "\n"
      ],
      "metadata": {
        "id": "yvRo67Io4NKF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Basic Part** (60%)\n",
        "In this part, your need to implement a Decision Tree model by completing the following given functions.\n",
        "\n",
        "Also, you need to run these functions with the given input variables and save the output in a csv file **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "wwVh8lYD4kbV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages\n",
        "\n",
        "\n",
        "> Note : You **cannot** import any other packages in both basic part and advanced part\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h2ibEyDa46X2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "from numpy import sqrt\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "RMjaYVZD6kmb"
      },
      "execution_count": 442,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_basic.csv**"
      ],
      "metadata": {
        "id": "zrQXqH475G8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = pd.read_csv('hw2_input_basic.csv')\n"
      ],
      "metadata": {
        "id": "0n3gcL2l6kjb"
      },
      "execution_count": 443,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global attributes\n",
        "Define the global attributes\n",
        "> Note : You **cannot** modify the values of these attributes we given in the basic part"
      ],
      "metadata": {
        "id": "BhtqUTG9Nlyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = input_data.shape[1] - 1"
      ],
      "metadata": {
        "id": "etfPC94oN_TO"
      },
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> You can add your own global attributes here"
      ],
      "metadata": {
        "id": "V1FN1Z-tOFOo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KQ-OYop8ONnv"
      },
      "execution_count": 444,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Calculate the Entropy and Information Gain \n",
        "Calculate the information gain and entropy values before separate data into left subtree and right subtree"
      ],
      "metadata": {
        "id": "Gey7t_Yx5YML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def entropy(data):\n",
        "  \"\"\"\n",
        "  This function measures the amount of uncertainty in a probability distribution\n",
        "  args: \n",
        "  * data(type: DataFrame): the data you're calculating for the entropy\n",
        "  return:\n",
        "  * entropy_value(type: float): the data's entropy\n",
        "  \"\"\"\n",
        "\n",
        "  \n",
        "  if data.empty:\n",
        "    return 0\n",
        "\n",
        "  freq_counts = data['diabetes_mellitus'].value_counts().to_dict()\n",
        "  count_patients = freq_counts.get(1, 0)\n",
        "  count_healthy = freq_counts.get(0, 0)\n",
        "\n",
        "\n",
        "  p = count_patients / (count_healthy + count_patients)\n",
        "  if p == 0:\n",
        "    p += 1e-9\n",
        "  elif p == 1:\n",
        "    p -= 1e-9\n",
        "  entropy_value = -p * math.log(p, 2) - (1 - p) * math.log(1 - p, 2)\n",
        "\n",
        "  return entropy_value\n",
        "\n",
        "# [Note] You have to save the value of \"ans_entropy\" into the output file\n",
        "ans_entropy = entropy(input_data)\n",
        "print(\"ans_entropy = \", ans_entropy)"
      ],
      "metadata": {
        "id": "hpdNz3ij6keH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee1dd3c-bb98-4fe9-ee0b-95759ed1ba5a"
      },
      "execution_count": 445,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_entropy =  0.9871377743721863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def information_gain(data, mask):\n",
        "  \"\"\"\n",
        "  This function will calculate the information gain\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you're calculating for the information gain\n",
        "  * mask(type: Series): partition information(left/right) of current input data, \n",
        "    - boolean 1(True) represents split to left subtree\n",
        "    - boolean 0(False) represents split to right subtree\n",
        "  return:\n",
        "  * ig(type: float): the information gain you can obtain by classify data with this given mask\n",
        "  \"\"\"\n",
        "\n",
        "  tmp_data = pd.DataFrame.copy(data)\n",
        "\n",
        "  tmp_data['mask'] = mask\n",
        "\n",
        "  left_tree_data = tmp_data.loc[tmp_data['mask'] == 1]\n",
        "  right_tree_data = tmp_data.loc[tmp_data['mask'] == 0]\n",
        "\n",
        "  \n",
        "\n",
        "  # in case the global input_data will have addition column\n",
        "\n",
        "  \n",
        "  left_tree_size = left_tree_data.shape[0]\n",
        "  right_tree_size = right_tree_data.shape[0]\n",
        "\n",
        "  new_entropy_val = ((left_tree_size * entropy(left_tree_data) + right_tree_size * entropy(right_tree_data)) \n",
        "              / (left_tree_size + right_tree_size))\n",
        "  \n",
        "\n",
        "  ig = entropy(data) - new_entropy_val\n",
        "\n",
        "  return ig\n",
        "\n",
        "# [Note] You have to save the value of \"ans_informationGain\" into your output file\n",
        "temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)\n",
        "temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)\n",
        "temp_mask = np.concatenate((temp1, temp2))\n",
        "df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n",
        "ans_informationGain = information_gain(input_data, df_mask['mask'])\n",
        "print(\"ans_informationGain = \", ans_informationGain)"
      ],
      "metadata": {
        "id": "zCC_SiU26kbX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ca2b16-9219-45c1-8f66-cf35465e864d"
      },
      "execution_count": 446,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_informationGain =  0.0834598868480716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Find the Best Split\n",
        "Find the best split combination, **feature** and **threshold**, by calculating the information gain\n"
      ],
      "metadata": {
        "id": "9r8mrn7A55if"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_best_split(data):\n",
        "  \"\"\"\n",
        "  This function will find the best split combination of data\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  return\n",
        "  * best_ig(type: float): the best information gain you obtain\n",
        "  * best_threshold(type: float): the value that splits data into 2 branches\n",
        "  * best_feature(type: string): the feature that splits data into 2 branches\n",
        "  \"\"\"\n",
        "\n",
        "  best_feature = \"\"\n",
        "  \n",
        "  for attr in data:\n",
        "    if attr == 'diabetes_mellitus':\n",
        "      continue\n",
        "    arr = sorted(set(data[attr]))\n",
        "    thres_arr = []\n",
        "    for idx in range(len(arr) - 1):\n",
        "      thres_arr.append((arr[idx] + arr[idx + 1]) / 2)\n",
        "    thres_arr.append(arr[0] - 1)\n",
        "    thres_arr.append(arr[-1] + 1)\n",
        "    for thres in thres_arr:\n",
        "      mask = [1 if x <= thres else 0 for x in data[attr]]\n",
        "\n",
        "\n",
        "      cur_ig = information_gain(data, pd.Series(mask))\n",
        "\n",
        "      if best_feature == \"\" or cur_ig > best_ig:\n",
        "        #check\n",
        "        #print(cur_ig)\n",
        "        #print(mask)\n",
        "\n",
        "        best_ig = cur_ig\n",
        "        best_feature = attr\n",
        "        best_threshold = thres\n",
        "  return best_ig, best_threshold, best_feature\n",
        "\n",
        "# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n",
        "ans_ig, ans_value, ans_name = find_best_split(input_data)\n",
        "print(\"ans_ig = \", ans_ig)\n",
        "print(\"ans_value = \", ans_value)\n",
        "print(\"ans_name = \", ans_name)"
      ],
      "metadata": {
        "id": "D6gg7ig18XgM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "627cff6d-4fe3-4956-b993-0177a1cc6c7c"
      },
      "execution_count": 447,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_ig =  0.3522950442685556\n",
            "ans_value =  235.5\n",
            "ans_name =  glucose_apache\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Split into 2 branches\n",
        "Using the best split combination you find in function *find_best_split()* to split data into Left Subtree and Right Subtree "
      ],
      "metadata": {
        "id": "61hPUYvy6MTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_partition(data, feature, threshold):\n",
        "  \"\"\"\n",
        "  This function will split the data into 2 branches\n",
        "  args:\n",
        "  * data(type: DataFrame): the input data\n",
        "  * feature(type: string): the attribute(column name)\n",
        "  * threshold(type: float): the threshold for splitting the data\n",
        "  return:\n",
        "  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n",
        "  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n",
        "  \"\"\"\n",
        "\n",
        "  tmp_data = pd.DataFrame.copy(data)\n",
        "  left = tmp_data.loc[tmp_data[feature] <= threshold]\n",
        "  right = tmp_data.loc[tmp_data[feature] > threshold]\n",
        "\n",
        "  left.reset_index(inplace = True, drop = True)\n",
        "  right.reset_index(inplace = True, drop = True)\n",
        "\n",
        "\n",
        "  return left, right\n",
        "\n",
        "\n",
        "# [Note] You have to save the value of \"ans_left\" into the output file\n",
        "left, right = make_partition(input_data, 'age', 61.0)\n",
        "ans_left = left.shape[0]\n",
        "print(\"ans_left = \", ans_left)"
      ],
      "metadata": {
        "id": "KQRcjzCLCo4R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57b1b1d3-b098-4865-f6d8-0887f71038f1"
      },
      "execution_count": 448,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_left =  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Build Decision Tree\n",
        "Use the above functions to implement the decision tree\n",
        "\n",
        "Instructions: \n",
        "1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n",
        "2.  Use function *find_best_split()* to find the best split combination\n",
        "3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n",
        "4. Use function *make_partition()* to split the data into two parts\n",
        "5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GLzy6Yhg802x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def majority(tree):\n",
        "  freq_counts = tree['diabetes_mellitus'].value_counts().to_dict()\n",
        "  count_patients = freq_counts.get(1, 0)\n",
        "  count_healthy = freq_counts.get(0, 0)\n",
        "\n",
        "  if count_patients >= count_healthy:\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n"
      ],
      "metadata": {
        "id": "gVjcOXKby4ZX"
      },
      "execution_count": 449,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_tree(data, max_depth, min_samples_split, depth):\n",
        "  \"\"\"\n",
        "  This function will build the decision tree\n",
        "  args:\n",
        "  * data(type: DataFrame): the data you want to apply to the decision tree\n",
        "  * max_depth: the maximum depth of a decision tree\n",
        "  * min_samples_split: the minimum number of instances required to do partition\n",
        "  * depth: the height of the current decision tree\n",
        "  return:\n",
        "  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n",
        "  \"\"\"\n",
        "\n",
        "  # check the condition of current depth and the remaining number of samples\n",
        "  if depth < max_depth and data.shape[0] > min_samples_split:\n",
        "    # call find_best_split() to find the best combination\n",
        "    information_gain, threshold, feature = find_best_split(data)\n",
        "    # check the value of information gain is greater than 0 or not \n",
        "    if information_gain > 0:\n",
        "      # update the depth\n",
        "      depth += 1\n",
        "      # call make_partition() to split the data into two parts\n",
        "      left_data, right_data = make_partition(data, feature, threshold)\n",
        "      # If there is no data split to the left tree OR no data split to the left tree\n",
        "      if left_data.shape[0] == 0 or right_data.shape[0] == 0:\n",
        "        # return the label of the majority\n",
        "        if left_data.shape[0] == 0:\n",
        "          label = majority(right_data)\n",
        "        else:\n",
        "          label = majority(left_data)\n",
        "        return label\n",
        "      else:\n",
        "        question = \"{} {} {}\".format(feature, \"<=\", threshold)\n",
        "        subtree = {question: []}\n",
        "\n",
        "        # call function build_tree() to recursively build the left subtree and right subtree\n",
        "        # depth has been updated at the top\n",
        "        left_subtree = build_tree(left_data, max_depth, min_samples_split, depth)\n",
        "        right_subtree = build_tree(right_data, max_depth, min_samples_split, depth)\n",
        "\n",
        "        if left_subtree == right_subtree:\n",
        "          subtree = left_subtree\n",
        "        else:\n",
        "          subtree[question].append(left_subtree)\n",
        "          subtree[question].append(right_subtree)\n",
        "    else:\n",
        "      # return the label of the majority\n",
        "      label = majority(data)\n",
        "      return label\n",
        "  else:\n",
        "    # return the label of the majority\n",
        "    label = majority(data)\n",
        "    return label\n",
        "\n",
        "  return subtree"
      ],
      "metadata": {
        "id": "_OAXVddKkvM2"
      },
      "execution_count": 450,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An example of the output from *build_tree()* \n",
        "```\n",
        "{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n",
        "```\n",
        "Therefore, \n",
        "```\n",
        "ans_features = ['bmi', 'age']\n",
        "ans_thresholds = [33.5, 68.5]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "qlIrw9Gu-M9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_features = []\n",
        "ans_thresholds = []\n",
        "\n",
        "decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n",
        "decisionTree"
      ],
      "metadata": {
        "id": "QW8wm1rD9dlS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "876d5fcf-f3b7-4a4c-efe4-39211b033283"
      },
      "execution_count": 451,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'glucose_apache <= 235.5': [{'heart_rate_apache <= 143.5': [0, 1]}, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 451
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n",
        "\n",
        "def get_features(tree):\n",
        "  if type(tree) != dict:\n",
        "    return None\n",
        "  for key, val in tree.items():\n",
        "    if (key.split()[1] == '<='):\n",
        "      ans_features.append(key.split()[0])\n",
        "      get_features(val[0])\n",
        "      get_features(val[1])\n",
        "\n",
        "ans_features = []\n",
        "get_features(decisionTree)\n",
        "ans_features"
      ],
      "metadata": {
        "id": "v_n0BfNSGejN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "976790b3-120c-4a3c-d213-8437b1511777"
      },
      "execution_count": 452,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glucose_apache', 'heart_rate_apache']"
            ]
          },
          "metadata": {},
          "execution_count": 452
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n",
        "\n",
        "def get_thresholds(tree):\n",
        "  if type(tree) != dict:\n",
        "    return None\n",
        "  for key, val in tree.items():\n",
        "    if (key.split()[1] == '<='):\n",
        "      ans_thresholds.append(key.split()[2])\n",
        "      get_thresholds(val[0])\n",
        "      get_thresholds(val[1])\n",
        "\n",
        "ans_thresholds = []\n",
        "get_thresholds(decisionTree)\n",
        "ans_thresholds"
      ],
      "metadata": {
        "id": "D6H9zkN_GgK-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa116898-d796-403a-ea3b-4a371a9b7a86"
      },
      "execution_count": 453,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['235.5', '143.5']"
            ]
          },
          "metadata": {},
          "execution_count": 453
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step6 : Save answers"
      ],
      "metadata": {
        "id": "rP0SU7tTweOX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basic = []\n",
        "basic.append(ans_entropy)\n",
        "basic.append(ans_informationGain)\n",
        "basic.append(ans_ig)\n",
        "basic.append(ans_value)\n",
        "basic.append(ans_name)\n",
        "basic.append(ans_left)\n",
        "for i in range(len(ans_features)):\n",
        "  basic.append(ans_features[i])\n",
        "for m in range(len(ans_thresholds)):\n",
        "  basic.append(ans_thresholds[m])"
      ],
      "metadata": {
        "id": "sDO36kKEwh6C"
      },
      "execution_count": 454,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step7 : Split data\n",
        "Split data into training set and validation set\n",
        "> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."
      ],
      "metadata": {
        "id": "7DotyrSZjYKi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_train = 20\n",
        "num_validation = 10\n",
        "\n",
        "training_data = input_data.iloc[:num_train] # 0 ~ 19\n",
        "validation_data = input_data.iloc[-num_validation:] # 20 ~ 29\n",
        "\n",
        "y_train = training_data[[\"diabetes_mellitus\"]]\n",
        "x_train = training_data.drop(['diabetes_mellitus'], axis=1)\n",
        "y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
        "x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
        "y_validation = y_validation.values.flatten()\n",
        "\n",
        "print(input_data.shape)\n",
        "print(training_data.shape)\n",
        "print(validation_data.shape)\n"
      ],
      "metadata": {
        "id": "WjNM-n4i5mlG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d593784-f0e0-4140-f8d1-642948cc5c6d"
      },
      "execution_count": 455,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30, 10)\n",
            "(20, 10)\n",
            "(10, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step8 to Step10 : Make predictions with a decision tree"
      ],
      "metadata": {
        "id": "GfKSt2gH74Uu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the decision tree\n",
        "> You **cannot** modify the values of these attributes in this part"
      ],
      "metadata": {
        "id": "BZqSVoJ48a3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_depth = 2\n",
        "depth = 0\n",
        "min_samples_split = 2\n",
        "n_features = x_train.shape[1]"
      ],
      "metadata": {
        "id": "vSlZ7FVB8eau"
      },
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have finished the function '*classify_data()*' below, however, you can modify this function if you prefer completing it on your own way."
      ],
      "metadata": {
        "id": "FrK-YqLmLH8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_data(instance, tree):\n",
        "  \"\"\"\n",
        "  This function will predict/classify the input instance\n",
        "  args:\n",
        "  * instance: a instance(case) to be predicted\n",
        "  return:\n",
        "  * answer: the prediction result (the classification result)\n",
        "  \"\"\"\n",
        "  equation = list(tree.keys())[0] \n",
        "  if equation.split()[1] == '<=':\n",
        "    temp_feature = equation.split()[0]\n",
        "    temp_threshold = equation.split()[2]\n",
        "    if instance[temp_feature] > float(temp_threshold):\n",
        "      answer = tree[equation][1]\n",
        "    else:\n",
        "      answer = tree[equation][0]\n",
        "  else:\n",
        "    if instance[equation.split()[0]] in (equation.split()[2]):\n",
        "      answer = tree[equation][0]\n",
        "    else:\n",
        "      answer = tree[equation][1]\n",
        "\n",
        "  if not isinstance(answer, dict):\n",
        "    return answer\n",
        "  else:\n",
        "    return classify_data(instance, answer)\n",
        "\n",
        "\n",
        "def make_prediction(tree, data):\n",
        "  \"\"\"\n",
        "  This function will use your pre-trained decision tree to predict the labels of all instances in data\n",
        "  args:\n",
        "  * tree: the decision tree\n",
        "  * data: the data to predict\n",
        "  return:\n",
        "  * y_prediction: the predictions\n",
        "  \"\"\"\n",
        "  \n",
        "  # [Note] You can call the function classify_data() to predict the label of each instance\n",
        "  y_prediction = []\n",
        "  for idx, row in data.iterrows():\n",
        "    y_prediction.append(classify_data(row, tree))\n",
        "  y_prediction = np.array(y_prediction)\n",
        "\n",
        "  return y_prediction\n",
        "\n",
        "\n",
        "def calculate_score(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  This function will calculate the f1-score of the predictions\n",
        "  args:\n",
        "  * y_true: the ground truth\n",
        "  * y_pred: the predictions\n",
        "  return:\n",
        "  * score: the f1-score\n",
        "  \"\"\"\n",
        "\n",
        "  # f1 score = 2 * (precision + recall) / (precision + recall)\n",
        "  # precision = TP / (TP + FP), recall = TP / (TP + FN)\n",
        "  \n",
        "  \n",
        "  TP, FP, FN = 0, 0, 0\n",
        "  for true, pred in zip(y_true, y_pred):\n",
        "    if true == 1 and pred == 1:\n",
        "      TP += 1\n",
        "    elif true == 0 and pred == 1:\n",
        "      FP += 1\n",
        "    elif true == 1 and pred == 0:\n",
        "      FN += 1\n",
        "\n",
        "  precision = TP / (TP + FP)\n",
        "  recall = TP / (TP + FN)\n",
        "  score = 2 * precision * recall / (precision + recall)\n",
        "  \n",
        "  return score"
      ],
      "metadata": {
        "id": "0piZ0blpFXVq"
      },
      "execution_count": 457,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n",
        "\n",
        "y_pred = make_prediction(decision_tree, x_validation)\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" the your output file\n",
        "ans_f1score = calculate_score(y_validation, y_pred)\n",
        "print(\"ans_f1score = \", ans_f1score)"
      ],
      "metadata": {
        "id": "3IEu3z3s9TDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7716b51-c8f4-40bc-ae1a-6b151ff1fb62"
      },
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_f1score =  0.6666666666666666\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step11 : Write the Output File\n",
        "Save all of your answers in a csv file, named as **hw2_basic.csv**"
      ],
      "metadata": {
        "id": "IzzOKOwn-kod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ans_path = 'hw2_basic.csv'\n",
        "\n",
        "# [Note] You have to save the value of \"ans_f1score\" into the output file\n",
        "basic.append(ans_f1score)\n",
        "print(basic)\n",
        "\n",
        "pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "p0zsaWPL2qXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9222dff-5fb2-4b71-ad5b-f31a9bed2a67"
      },
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.9871377743721863, 0.0834598868480716, 0.3522950442685556, 235.5, 'glucose_apache', 10, 'glucose_apache', 'heart_rate_apache', '235.5', '143.5', 0.6666666666666666]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Advanced Part** (35%)"
      ],
      "metadata": {
        "id": "tV25IjM7_aEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step1: Load the input data\n",
        "First, load the input file **hw2_input_advanced.csv**"
      ],
      "metadata": {
        "id": "knH1Ih0Pha7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_data = pd.read_csv('hw2_input_advanced.csv')"
      ],
      "metadata": {
        "id": "FthBdLxRhi9W"
      },
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can split *advanced_data* into training set and validaiton set"
      ],
      "metadata": {
        "id": "vqLH49oBndRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_size = advanced_data.shape[0]\n",
        "training_data = advanced_data.iloc[:int(total_size / 10 * 7.5)]\n",
        "validation_data = advanced_data.iloc[int(total_size / 10 * 7.5):] \n",
        "\n",
        "validation_data.reset_index(inplace = True, drop = True)\n",
        "\n",
        "###\n",
        "y_validation = validation_data[[\"diabetes_mellitus\"]]\n",
        "x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n",
        "y_validation = y_validation.values.flatten()\n",
        "\n",
        "###\n",
        "\n",
        "#print(training_data.shape, '\\n')\n",
        "#print(validation_data.shape)\n"
      ],
      "metadata": {
        "id": "9l0hLPVjncam"
      },
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step2 : Load the test data\n",
        "Load the input file **hw2_input_test.csv** to make predictions with the pre-trained random forest model"
      ],
      "metadata": {
        "id": "tFgbUY_ajVOK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = pd.read_csv('hw2_input_test.csv')\n"
      ],
      "metadata": {
        "id": "3hW542KWNxVF"
      },
      "execution_count": 462,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step3 : Build a Random Forest"
      ],
      "metadata": {
        "id": "mH-0DxyR9qWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the attributions of the random forest\n",
        "> * You **can** modify the values of these attributes in advanced part\n",
        "> * Each tree can have different attribute values\n",
        "> * There must be **at least** 3 decision trees in the random forest model\n",
        "> * Must use function *build_tree()* to build a random forest model\n",
        "> * These are the parameters you can adjust : \n",
        "\n",
        "\n",
        "    ```\n",
        "    max_depth = \n",
        "    depth = 0\n",
        "    min_samples_split = \n",
        "    \n",
        "    # total number of trees in a random forest\n",
        "    n_trees = \n",
        "\n",
        "    # number of features to train a decision tree\n",
        "    n_features = \n",
        "\n",
        "    # the ratio to select the number of instances\n",
        "    sample_size = \n",
        "    n_samples = int(training_data.shape[0] * sample_size)\n",
        "    ```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8xbLxFW597FG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the attributes\n",
        "max_depth = 3\n",
        "depth = 0\n",
        "min_samples_split = 200\n",
        "\n",
        "n_trees = 99\n",
        "\n",
        "n_features = 5\n",
        "\n",
        "sample_size = 0.8\n",
        "n_samples = int(training_data.shape[0] * sample_size)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LD8ndJ8ymzG3"
      },
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_forest(data, n_trees, n_features, n_samples):\n",
        "  \"\"\"\n",
        "  This function will build a random forest.\n",
        "  args:\n",
        "  * data: all data that can be used to train a random forest\n",
        "  * n_trees: total number of tree\n",
        "  * n_features: number of features\n",
        "  * n_samples: number of instances\n",
        "  return:\n",
        "  * forest: a random forest with 'n_trees' of decision tree\n",
        "  \"\"\"\n",
        "\n",
        "  forest = []\n",
        "\n",
        "  tmp_data = pd.DataFrame.copy(data)\n",
        "\n",
        "  # must reuse function build_tree()\n",
        "  for i in range(n_trees):\n",
        "    feature_idx = random.sample(range(training_data.shape[1] - 1), n_features) #exclusive 0 ~ 23, no duplicates\n",
        "    feature_idx.append(24)\n",
        "    row_idx = []\n",
        "    for j in range(n_samples):\n",
        "      row_idx.append(random.randint(0, training_data.shape[0] - 1)) #inclusive\n",
        "\n",
        "    new_data = tmp_data.iloc[row_idx, feature_idx]\n",
        "    new_data.reset_index(inplace = True, drop = True)\n",
        "    \n",
        "    tree = build_tree(new_data, max_depth, min_samples_split, depth)\n",
        "    forest.append(tree)\n",
        "\n",
        "  return forest"
      ],
      "metadata": {
        "id": "hVl66f1aU36-"
      },
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "forest = build_forest(training_data, n_trees, n_features, n_samples)"
      ],
      "metadata": {
        "id": "zylo6C51m3OJ"
      },
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(forest)"
      ],
      "metadata": {
        "id": "bcDNOufJ8OeZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db0bd52a-8bbe-41ae-bf65-bf6028b3f2bb"
      },
      "execution_count": 466,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'age <= 38.5': [0, {'bmi <= 26.634992245': [0, 1]}]}, {'creatinine_apache <= 1.355': [{'map_apache <= 72.5': [{'creatinine_apache <= 0.46499999999999997': [1, 0]}, {'creatinine_apache <= 0.555': [1, 0]}]}, {'creatinine_apache <= 8.385': [1, 0]}]}, {'resprate_apache <= 13.5': [{'age <= 20.5': [0, 1]}, {'bun_apache <= 15.5': [0, {'resprate_apache <= 37.5': [1, 0]}]}]}, {'bun_apache <= 19.5': [0, {'age <= 82.5': [{'bun_apache <= 91.5': [1, 0]}, 0]}]}, {'resprate_apache <= 15.5': [{'age <= 36.5': [0, {'age <= 88.5': [1, 0]}]}, {'creatinine_apache <= 1.1749999999999998': [{'creatinine_apache <= 0.525': [1, 0]}, {'resprate_apache <= 34.5': [1, 0]}]}]}, {'bmi <= 25.16594881': [{'gcs_verbal_apache <= 1.5': [{'map_apache <= 65.5': [1, 0]}, 0]}, {'gcs_verbal_apache <= 2.5': [1, {'map_apache <= 77.5': [1, 0]}]}]}, {'age <= 39.5': [0, {'age <= 60.5': [{'gcs_motor_apache <= 1.5': [1, 0]}, {'gcs_eyes_apache <= 3.5': [1, 0]}]}]}, {'age <= 57.5': [{'creatinine_apache <= 1.4449999999999998': [{'creatinine_apache <= 0.495': [1, 0]}, {'age <= 40.5': [0, 1]}]}, {'age <= 76.5': [1, 0]}]}, {'creatinine_apache <= 1.4649999999999999': [{'map_apache <= 74.5': [0, {'creatinine_apache <= 0.555': [1, 0]}]}, {'heart_rate_apache <= 125.5': [1, {'sodium_apache <= 139.5': [1, 0]}]}]}, {'map_apache <= 103.5': [{'gcs_eyes_apache <= 3.5': [{'apache_4a_hospital_death_prob <= 0.295': [1, 0]}, 0]}, {'apache_4a_hospital_death_prob <= 0.025': [{'map_apache <= 177.5': [0, 1]}, 0]}]}, {'creatinine_apache <= 1.705': [{'creatinine_apache <= 0.595': [1, 0]}, {'creatinine_apache <= 2.495': [1, {'creatinine_apache <= 2.755': [0, 1]}]}]}, {'glucose_apache <= 169.5': [0, {'apache_4a_icu_death_prob <= 0.245': [1, {'glucose_apache <= 351.5': [0, 1]}]}]}, {'age <= 58.5': [{'creatinine_apache <= 1.475': [{'creatinine_apache <= 0.535': [1, 0]}, {'age <= 26.5': [0, 1]}]}, {'age <= 78.5': [{'creatinine_apache <= 1.3450000000000002': [0, 1]}, 0]}]}, {'bun_apache <= 19.5': [{'hematocrit_apache <= 31.15': [{'hematocrit_apache <= 20.4': [0, 1]}, 0]}, {'hematocrit_apache <= 37.75': [{'bun_apache <= 86.5': [1, 0]}, {'bun_apache <= 35.5': [0, 1]}]}]}, {'hematocrit_apache <= 38.150000000000006': [{'heart_rate_apache <= 117.5': [{'gcs_eyes_apache <= 3.5': [1, 0]}, 0]}, {'gcs_motor_apache <= 4.5': [0, {'gcs_eyes_apache <= 1.5': [1, 0]}]}]}, {'resprate_apache <= 32.5': [{'bun_apache <= 19.5': [{'resprate_apache <= 13.5': [1, 0]}, 1]}, {'bun_apache <= 25.5': [0, {'resprate_apache <= 43.5': [1, 0]}]}]}, {'glucose_apache <= 169.5': [{'glucose_apache <= 86.5': [{'weight <= 82.05': [0, 1]}, 0]}, 1]}, {'age <= 36.5': [0, {'age <= 59.5': [0, {'age <= 75.5': [1, 0]}]}]}, {'resprate_apache <= 32.5': [{'resprate_apache <= 15.5': [{'age <= 36.5': [0, 1]}, {'resprate_apache <= 22.5': [0, 1]}]}, 0]}, {'glucose_apache <= 169.5': [0, {'glucose_apache <= 220.5': [{'heart_rate_apache <= 123.5': [1, 0]}, 1]}]}, {'bmi <= 25.19076532': [{'age <= 62.5': [0, {'gcs_motor_apache <= 5.5': [1, 0]}]}, {'age <= 52.5': [0, {'bmi <= 28.467890609999998': [0, 1]}]}]}, {'glucose_apache <= 169.5': [{'ventilated_apache <= 0.5': [{'glucose_apache <= 71.5': [1, 0]}, {'glucose_apache <= 97.5': [1, 0]}]}, {'glucose_apache <= 216.5': [{'heart_rate_apache <= 123.5': [1, 0]}, 1]}]}, {'creatinine_apache <= 1.335': [{'creatinine_apache <= 0.535': [{'temp_apache <= 35.3': [0, 1]}, 0]}, {'temp_apache <= 34.45': [0, {'apache_4a_hospital_death_prob <= 0.785': [1, 0]}]}]}, {'age <= 62.5': [{'arf_apache <= 0.5': [0, 1]}, {'arf_apache <= 0.5': [{'age <= 84.5': [1, 0]}, 1]}]}, {'hematocrit_apache <= 35.75': [{'gcs_eyes_apache <= 3.5': [{'hematocrit_apache <= 31.95': [1, 0]}, {'hematocrit_apache <= 35.650000000000006': [0, 1]}]}, 0]}, {'glucose_apache <= 169.5': [0, {'glucose_apache <= 222.5': [1, {'hematocrit_apache <= 20.25': [0, 1]}]}]}, {'bmi <= 26.673437149999998': [{'wbc_apache <= 11.05': [0, {'bmi <= 23.244664354999998': [0, 1]}]}, {'hematocrit_apache <= 38.05': [1, 0]}]}, {'age <= 39.5': [{'wbc_apache <= 4.45': [0, {'wbc_apache <= 4.55': [1, 0]}]}, {'hematocrit_apache <= 35.95': [{'hematocrit_apache <= 20.15': [0, 1]}, 0]}]}, {'glucose_apache <= 164.5': [{'resprate_apache <= 13.5': [{'glucose_apache <= 86.5': [1, 0]}, 0]}, {'glucose_apache <= 222.5': [{'resprate_apache <= 31.5': [1, 0]}, 1]}]}, {'glucose_apache <= 169.5': [{'gcs_verbal_apache <= 1.5': [{'hematocrit_apache <= 31.05': [1, 0]}, {'glucose_apache <= 66.5': [1, 0]}]}, {'glucose_apache <= 198.5': [{'gcs_eyes_apache <= 3.5': [1, 0]}, 1]}]}, {'glucose_apache <= 164.5': [{'age <= 54.5': [0, {'glucose_apache <= 86.5': [1, 0]}]}, {'glucose_apache <= 222.5': [{'age <= 35.5': [0, 1]}, 1]}]}, {'glucose_apache <= 169.5': [{'glucose_apache <= 86.5': [{'ventilated_apache <= 0.5': [0, 1]}, 0]}, 1]}, {'gcs_verbal_apache <= 2.5': [1, {'creatinine_apache <= 1.2650000000000001': [{'creatinine_apache <= 0.615': [1, 0]}, {'gcs_verbal_apache <= 3.5': [0, 1]}]}]}, {'resprate_apache <= 32.5': [{'resprate_apache <= 13.5': [1, {'resprate_apache <= 23.5': [0, 1]}]}, 0]}, {'age <= 39.5': [0, {'hematocrit_apache <= 32.75': [1, 0]}]}, {'age <= 36.5': [{'creatinine_apache <= 0.575': [1, {'sodium_apache <= 151.5': [0, 1]}]}, {'map_apache <= 75.5': [{'heart_rate_apache <= 121.5': [1, 0]}, 0]}]}, {'bmi <= 23.836681015': [0, {'temp_apache <= 36.21': [{'temp_apache <= 34.650000000000006': [0, 1]}, {'bmi <= 36.659412845': [0, 1]}]}]}, {'age <= 59.5': [{'map_apache <= 65.5': [{'wbc_apache <= 8.25': [0, 1]}, 0]}, {'age <= 80.5': [{'map_apache <= 77.5': [1, 0]}, 0]}]}, {'glucose_apache <= 169.5': [{'resprate_apache <= 13.5': [{'arf_apache <= 0.5': [0, 1]}, 0]}, {'resprate_apache <= 34.5': [1, {'glucose_apache <= 259.0': [0, 1]}]}]}, {'heart_rate_apache <= 125.5': [{'apache_4a_hospital_death_prob <= 0.025': [0, {'heart_rate_apache <= 103.5': [1, 0]}]}, 0]}, {'glucose_apache <= 164.5': [{'hematocrit_apache <= 33.150000000000006': [{'heart_rate_apache <= 95.5': [1, 0]}, {'glucose_apache <= 70.5': [1, 0]}]}, {'glucose_apache <= 232.5': [{'heart_rate_apache <= 116.5': [1, 0]}, {'hematocrit_apache <= 20.1': [0, 1]}]}]}, {'arf_apache <= 0.5': [0, 1]}, {'glucose_apache <= 169.5': [{'age <= 49.5': [0, {'glucose_apache <= 75.5': [1, 0]}]}, {'glucose_apache <= 208.5': [{'age <= 37.5': [0, 1]}, 1]}]}, {'hematocrit_apache <= 33.45': [{'ventilated_apache <= 0.5': [{'apache_4a_icu_death_prob <= 0.015': [0, 1]}, {'wbc_apache <= 1.2999999999999998': [0, 1]}]}, 0]}, {'hematocrit_apache <= 35.349999999999994': [{'ventilated_apache <= 0.5': [{'hematocrit_apache <= 35.25': [0, 1]}, {'gcs_eyes_apache <= 3.5': [1, 0]}]}, 0]}, {'resprate_apache <= 13.5': [1, 0]}, {'bun_apache <= 19.5': [{'height <= 170.19': [{'height <= 167.85': [0, 1]}, 0]}, {'arf_apache <= 0.5': [{'height <= 182.84': [1, 0]}, 1]}]}, {'age <= 59.5': [{'weight <= 108.95': [0, {'weight <= 111.35': [1, 0]}]}, {'weight <= 77.155': [0, {'age <= 80.5': [1, 0]}]}]}, {'glucose_apache <= 169.5': [0, {'glucose_apache <= 215.5': [{'sodium_apache <= 151.5': [1, 0]}, 1]}]}, {'map_apache <= 88.5': [{'creatinine_apache <= 0.525': [1, {'creatinine_apache <= 1.105': [0, 1]}]}, {'creatinine_apache <= 1.205': [{'creatinine_apache <= 0.595': [1, 0]}, 0]}]}, {'resprate_apache <= 13.5': [{'age <= 49.5': [0, 1]}, 0]}, {'bmi <= 26.63461256': [{'temp_apache <= 36.315': [{'hematocrit_apache <= 35.150000000000006': [1, 0]}, 0]}, {'hematocrit_apache <= 38.05': [1, 0]}]}, {'glucose_apache <= 169.5': [{'glucose_apache <= 82.5': [{'bun_apache <= 13.5': [0, 1]}, 0]}, 1]}, {'age <= 40.5': [0, {'hematocrit_apache <= 36.05': [{'gcs_eyes_apache <= 3.5': [1, 0]}, 0]}]}, {'glucose_apache <= 164.5': [{'age <= 57.5': [0, {'glucose_apache <= 80.5': [1, 0]}]}, {'glucose_apache <= 222.5': [{'age <= 35.5': [0, 1]}, 1]}]}, {'creatinine_apache <= 1.185': [{'creatinine_apache <= 0.595': [1, {'temp_apache <= 36.105000000000004': [1, 0]}]}, {'apache_4a_icu_death_prob <= 0.485': [{'temp_apache <= 33.95': [0, 1]}, 0]}]}, {'bmi <= 26.635232005': [0, {'hematocrit_apache <= 37.45': [1, 0]}]}, {'glucose_apache <= 169.5': [{'age <= 52.5': [0, {'glucose_apache <= 86.5': [1, 0]}]}, 1]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 80.5': [{'weight <= 64.405': [0, 1]}, 0]}, {'glucose_apache <= 221.5': [{'weight <= 80.77': [0, 1]}, 1]}]}, {'bun_apache <= 19.5': [0, {'bun_apache <= 27.5': [0, {'age <= 80.5': [1, 0]}]}]}, {'weight <= 83.955': [{'creatinine_apache <= 1.545': [{'creatinine_apache <= 0.496': [1, 0]}, {'creatinine_apache <= 8.08': [1, 0]}]}, {'creatinine_apache <= 0.595': [1, {'gcs_eyes_apache <= 3.5': [1, 0]}]}]}, {'bun_apache <= 19.5': [{'weight <= 86.62': [0, {'gcs_verbal_apache <= 1.5': [1, 0]}]}, {'weight <= 68.11': [0, 1]}]}, {'bun_apache <= 19.5': [0, {'map_apache <= 108.5': [1, {'height <= 182.84': [1, 0]}]}]}, {'bmi <= 27.477734005': [{'arf_apache <= 0.5': [0, 1]}, {'age <= 62.5': [0, 1]}]}, {'bmi <= 26.63461256': [0, {'hematocrit_apache <= 32.650000000000006': [1, 0]}]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 75.5': [{'gcs_motor_apache <= 4.5': [0, 1]}, 0]}, 1]}, {'glucose_apache <= 167.5': [{'glucose_apache <= 75.5': [{'gcs_motor_apache <= 4.5': [0, 1]}, 0]}, 1]}, {'bmi <= 23.79989888': [{'creatinine_apache <= 0.495': [1, 0]}, {'creatinine_apache <= 0.475': [1, {'bmi <= 33.891305955': [0, 1]}]}]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 82.5': [{'height <= 163.5': [0, 1]}, 0]}, {'glucose_apache <= 220.5': [{'height <= 182.84': [1, 0]}, 1]}]}, {'bmi <= 26.635232005': [{'creatinine_apache <= 0.475': [1, 0]}, {'age <= 58.5': [{'creatinine_apache <= 1.205': [0, 1]}, 1]}]}, {'age <= 39.5': [0, {'age <= 63.5': [0, {'age <= 77.5': [1, 0]}]}]}, {'glucose_apache <= 167.5': [{'age <= 51.5': [0, {'gcs_verbal_apache <= 1.5': [1, 0]}]}, 1]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 86.5': [{'weight <= 86.35': [0, 1]}, 0]}, {'glucose_apache <= 237.5': [{'weight <= 58.6': [0, 1]}, 1]}]}, {'bun_apache <= 19.5': [0, {'bmi <= 24.063718575': [0, {'heart_rate_apache <= 125.5': [1, 0]}]}]}, {'bun_apache <= 18.5': [{'arf_apache <= 0.5': [0, 1]}, {'arf_apache <= 0.5': [{'apache_4a_icu_death_prob <= 0.445': [1, 0]}, 1]}]}, {'bun_apache <= 19.5': [{'age <= 44.5': [{'temp_apache <= 39.155': [0, 1]}, 0]}, {'age <= 84.5': [{'age <= 64.5': [0, 1]}, 0]}]}, {'resprate_apache <= 30.5': [{'bun_apache <= 22.5': [{'resprate_apache <= 13.5': [1, 0]}, 1]}, 0]}, {'resprate_apache <= 32.5': [{'resprate_apache <= 13.5': [1, {'resprate_apache <= 23.5': [0, 1]}]}, {'creatinine_apache <= 1.3250000000000002': [{'creatinine_apache <= 0.39': [1, 0]}, {'resprate_apache <= 41.5': [1, 0]}]}]}, {'bun_apache <= 19.5': [{'creatinine_apache <= 0.555': [1, 0]}, {'height <= 182.84': [1, 0]}]}, {'arf_apache <= 0.5': [{'heart_rate_apache <= 147.5': [0, {'height <= 194.0': [0, 1]}]}, 1]}, {'resprate_apache <= 34.5': [{'bmi <= 23.836681015': [{'resprate_apache <= 13.5': [1, 0]}, {'apache_4a_icu_death_prob <= 0.015': [0, 1]}]}, 0]}, {'bun_apache <= 18.5': [{'height <= 170.19': [{'height <= 167.82': [0, 1]}, 0]}, {'gcs_verbal_apache <= 1.5': [{'ventilated_apache <= 0.5': [0, 1]}, {'bun_apache <= 25.5': [0, 1]}]}]}, {'bmi <= 28.376180660000003': [0, {'heart_rate_apache <= 142.5': [1, 0]}]}, {'gcs_verbal_apache <= 1.5': [{'apache_4a_hospital_death_prob <= 0.315': [1, {'apache_4a_hospital_death_prob <= 0.345': [0, 1]}]}, {'weight <= 77.155': [0, {'apache_4a_hospital_death_prob <= 0.025': [0, 1]}]}]}, {'bun_apache <= 19.5': [{'arf_apache <= 0.5': [0, 1]}, {'heart_rate_apache <= 100.5': [1, {'arf_apache <= 0.5': [0, 1]}]}]}, {'glucose_apache <= 186.5': [{'resprate_apache <= 13.5': [{'hematocrit_apache <= 38.849999999999994': [1, 0]}, 0]}, {'resprate_apache <= 32.5': [1, {'glucose_apache <= 235.5': [0, 1]}]}]}, {'age <= 36.5': [{'creatinine_apache <= 0.555': [1, 0]}, {'arf_apache <= 0.5': [0, {'creatinine_apache <= 1.98': [0, 1]}]}]}, {'bmi <= 28.376180660000003': [{'bmi <= 24.089540925': [0, {'gcs_verbal_apache <= 4.5': [1, 0]}]}, {'age <= 57.5': [0, {'age <= 81.5': [1, 0]}]}]}, {'glucose_apache <= 169.5': [{'bmi <= 28.420642864999998': [0, {'glucose_apache <= 86.5': [1, 0]}]}, {'glucose_apache <= 220.5': [{'apache_4a_icu_death_prob <= 0.515': [1, 0]}, 1]}]}, {'weight <= 77.235': [{'height <= 170.19': [{'height <= 168.95': [0, 1]}, 0]}, {'height <= 175.28': [1, {'map_apache <= 105.5': [1, 0]}]}]}, {'age <= 63.5': [0, {'heart_rate_apache <= 123.5': [{'age <= 84.5': [1, 0]}, {'hematocrit_apache <= 22.95': [1, 0]}]}]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 86.5': [{'map_apache <= 55.5': [1, 0]}, 0]}, {'glucose_apache <= 216.5': [{'map_apache <= 78.5': [1, 0]}, 1]}]}, {'bun_apache <= 13.5': [{'creatinine_apache <= 0.555': [{'creatinine_apache <= 0.496': [1, 0]}, 0]}, {'gcs_verbal_apache <= 2.5': [1, {'bun_apache <= 19.5': [0, 1]}]}]}, {'resprate_apache <= 34.5': [{'apache_4a_hospital_death_prob <= 0.055': [{'resprate_apache <= 13.5': [1, 0]}, 1]}, {'creatinine_apache <= 1.2650000000000001': [{'creatinine_apache <= 0.395': [1, 0]}, {'gcs_verbal_apache <= 2.5': [1, 0]}]}]}, {'glucose_apache <= 164.5': [{'glucose_apache <= 86.5': [{'glucose_apache <= 69.5': [1, 0]}, 0]}, {'glucose_apache <= 204.5': [{'glucose_apache <= 202.5': [1, 0]}, 1]}]}, {'bun_apache <= 16.5': [{'creatinine_apache <= 0.555': [1, 0]}, {'bun_apache <= 25.5': [{'creatinine_apache <= 0.595': [1, 0]}, {'apache_4a_hospital_death_prob <= 0.305': [1, 0]}]}]}, {'glucose_apache <= 164.5': [0, {'glucose_apache <= 222.5': [{'age <= 26.5': [0, 1]}, 1]}]}, {'resprate_apache <= 29.5': [{'age <= 49.5': [{'temp_apache <= 36.650000000000006': [1, 0]}, {'resprate_apache <= 15.5': [1, 0]}]}, {'age <= 56.5': [0, {'gcs_verbal_apache <= 1.5': [1, 0]}]}]}, {'glucose_apache <= 169.5': [{'map_apache <= 60.5': [0, {'glucose_apache <= 64.5': [1, 0]}]}, {'glucose_apache <= 195.5': [{'map_apache <= 80.5': [1, 0]}, 1]}]}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step4 : Make predictions with the random forest\n",
        "> Note: Please print the f1-score of the predictions of each decision tree"
      ],
      "metadata": {
        "id": "dZb6EEYnnO05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_scores_of_predictions(forest):\n",
        "  sum = 0\n",
        "  for tree in forest:\n",
        "    y_pred = make_prediction(tree, x_validation)\n",
        "    ans_f1score = calculate_score(y_validation, y_pred)\n",
        "\n",
        "    #print(len(y_pred))\n",
        "    print(\"ans_f1score = \", ans_f1score)\n",
        "    sum += ans_f1score\n",
        "  #print(sum / n_trees)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "M-dYy0Ab__6Z"
      },
      "execution_count": 473,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "function of printing f1_scores of each decision tree for validation data"
      ],
      "metadata": {
        "id": "yYmaWSCBzhAV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print_scores_of_predictions(forest)"
      ],
      "metadata": {
        "id": "lpLqLVogFOKR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50238b20-c71b-4d4b-e10d-4417e5bee40a"
      },
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ans_f1score =  0.5830572645527685\n",
            "ans_f1score =  0.4892655367231638\n",
            "ans_f1score =  0.6303360581289736\n",
            "ans_f1score =  0.5372972972972972\n",
            "ans_f1score =  0.5813360530341662\n",
            "ans_f1score =  0.5604060913705584\n",
            "ans_f1score =  0.3717059639389736\n",
            "ans_f1score =  0.580885780885781\n",
            "ans_f1score =  0.45018450184501846\n",
            "ans_f1score =  0.24232887490165225\n",
            "ans_f1score =  0.46172839506172836\n",
            "ans_f1score =  0.627473148671566\n",
            "ans_f1score =  0.4399494310998736\n",
            "ans_f1score =  0.5875232774674114\n",
            "ans_f1score =  0.33602347762289064\n",
            "ans_f1score =  0.6197718631178706\n",
            "ans_f1score =  0.6988551518168242\n",
            "ans_f1score =  0.4897050639955481\n",
            "ans_f1score =  0.6237188872620791\n",
            "ans_f1score =  0.6465324384787472\n",
            "ans_f1score =  0.5346215780998389\n",
            "ans_f1score =  0.6970748636588994\n",
            "ans_f1score =  0.5005586592178771\n",
            "ans_f1score =  0.5565899069083783\n",
            "ans_f1score =  0.3167420814479638\n",
            "ans_f1score =  0.6515397082658023\n",
            "ans_f1score =  0.5715681485100147\n",
            "ans_f1score =  0.5829596412556053\n",
            "ans_f1score =  0.683433570256971\n",
            "ans_f1score =  0.6691608765366114\n",
            "ans_f1score =  0.7125237191650854\n",
            "ans_f1score =  0.6930395593390085\n",
            "ans_f1score =  0.5941765241128298\n",
            "ans_f1score =  0.6195811008280564\n",
            "ans_f1score =  0.5211930926216641\n",
            "ans_f1score =  0.508714596949891\n",
            "ans_f1score =  0.4693627450980392\n",
            "ans_f1score =  0.48172757475083056\n",
            "ans_f1score =  0.6403712296983759\n",
            "ans_f1score =  0.4478340451494814\n",
            "ans_f1score =  0.656426011264721\n",
            "ans_f1score =  0.12761904761904763\n",
            "ans_f1score =  0.694147582697201\n",
            "ans_f1score =  0.5041186161449752\n",
            "ans_f1score =  0.29571984435797666\n",
            "ans_f1score =  0.473717542748575\n",
            "ans_f1score =  0.5705458290422246\n",
            "ans_f1score =  0.47116564417177914\n",
            "ans_f1score =  0.6634563937934724\n",
            "ans_f1score =  0.46838407494145207\n",
            "ans_f1score =  0.4350781781101292\n",
            "ans_f1score =  0.5799715234931181\n",
            "ans_f1score =  0.6896891958559448\n",
            "ans_f1score =  0.38630136986301367\n",
            "ans_f1score =  0.6986640277090549\n",
            "ans_f1score =  0.5763182238667901\n",
            "ans_f1score =  0.535733769776323\n",
            "ans_f1score =  0.7067812798471824\n",
            "ans_f1score =  0.6666666666666667\n",
            "ans_f1score =  0.46063760572543916\n",
            "ans_f1score =  0.4885496183206107\n",
            "ans_f1score =  0.547915538711424\n",
            "ans_f1score =  0.5671039354187689\n",
            "ans_f1score =  0.48210922787193977\n",
            "ans_f1score =  0.41860465116279066\n",
            "ans_f1score =  0.6914682539682541\n",
            "ans_f1score =  0.6904164576016056\n",
            "ans_f1score =  0.42629227823867266\n",
            "ans_f1score =  0.6841584158415841\n",
            "ans_f1score =  0.5730279898218829\n",
            "ans_f1score =  0.455410225921522\n",
            "ans_f1score =  0.7010710808179164\n",
            "ans_f1score =  0.6909458775923116\n",
            "ans_f1score =  0.4796044499381953\n",
            "ans_f1score =  0.5625308947108254\n",
            "ans_f1score =  0.40235140431090793\n",
            "ans_f1score =  0.5473801560758084\n",
            "ans_f1score =  0.64049955396967\n",
            "ans_f1score =  0.5833333333333333\n",
            "ans_f1score =  0.12761904761904763\n",
            "ans_f1score =  0.535796766743649\n",
            "ans_f1score =  0.5544554455445544\n",
            "ans_f1score =  0.5232375979112271\n",
            "ans_f1score =  0.5736738703339882\n",
            "ans_f1score =  0.42040816326530617\n",
            "ans_f1score =  0.6677034733022291\n",
            "ans_f1score =  0.14111006585136407\n",
            "ans_f1score =  0.5272013460459899\n",
            "ans_f1score =  0.6954773869346733\n",
            "ans_f1score =  0.5628442663995994\n",
            "ans_f1score =  0.4918401800787845\n",
            "ans_f1score =  0.6523143164693218\n",
            "ans_f1score =  0.6092533211177279\n",
            "ans_f1score =  0.6146245059288538\n",
            "ans_f1score =  0.6897590361445782\n",
            "ans_f1score =  0.49414519906323184\n",
            "ans_f1score =  0.6694560669456067\n",
            "ans_f1score =  0.5417142857142857\n",
            "ans_f1score =  0.6600660066006601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_prediction_forest(forest, data):\n",
        "  \"\"\"\n",
        "  This function will use the pre-trained random forest to make the predictions\n",
        "  args:\n",
        "  * forest: the random forest\n",
        "  * data: the data used to predict\n",
        "  return:\n",
        "  * y_prediction: the predicted results\n",
        "  \"\"\"\n",
        "  y_prediction = [0] * data.shape[0]\n",
        "  \n",
        "  for tree in forest:\n",
        "    predictions_of_each_tree = list(make_prediction(tree, data))\n",
        "    y_prediction = [y_prediction[i] + predictions_of_each_tree[i] for i in range(data.shape[0])]\n",
        "  \n",
        "  \n",
        "  y_prediction = [1 if x >= (n_trees / 2) else 0 for x in y_prediction]\n",
        "  \n",
        "  return y_prediction"
      ],
      "metadata": {
        "id": "UbHMZnMDnWpG"
      },
      "execution_count": 469,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_test = make_prediction_forest(forest, x_test)"
      ],
      "metadata": {
        "id": "Hcd70ubwgHq4"
      },
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step5 : Write the Output File\n",
        "Save your predictions from the **random forest** in a csv file, named as **hw2_advanced.csv**"
      ],
      "metadata": {
        "id": "2ufa5bP9HveO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "advanced = []\n",
        "for i in range(len(y_pred_test)):\n",
        "  advanced.append(y_pred_test[i])"
      ],
      "metadata": {
        "id": "XdAQcE41JJYB"
      },
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "advanced_path = 'hw2_advanced.csv'\n",
        "pd.DataFrame(advanced).to_csv(advanced_path, header = None, index = None)"
      ],
      "metadata": {
        "id": "Pq121klSHwWO"
      },
      "execution_count": 472,
      "outputs": []
    }
  ]
}